{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac5dec66",
   "metadata": {},
   "source": [
    "# Data Manipulation and Feature Builidng\n",
    "\n",
    "\n",
    "## Spectator Liveliness Score — **SLS-F+** (FotMob, z-standardized)\n",
    "\n",
    "### Notation (per match)\n",
    "- Teams: $t \\in \\{\\mathrm{H}, \\mathrm{A}\\}$ = Home, Away  \n",
    "- Minutes played:  \n",
    "  $$ M \\;=\\; 90 \\;+\\; \\Delta_{45} \\;+\\; \\Delta_{90} $$\n",
    "  where $\\Delta_{45}$, $\\Delta_{90}$ are added-time minutes at 45′ and 90′ (fallback $M=95$ if unknown).\n",
    "\n",
    "- Per team raw stats (from the match JSON, Period = “All”):  \n",
    "  $\\mathrm{xG}_t$, $\\mathrm{Shots}_t$, $\\mathrm{SoT}_t$ (shots on target), $\\mathrm{BigCh}_t$ (big chances), $\\mathrm{Corners}_t$, $\\mathrm{ToB}_t$ (touches in opposition box; fallback: $\\mathrm{SiB}_t$ = shots inside box).\n",
    "\n",
    "- Attendance & capacity: $A$ (attendance), $C$ (stadium capacity); occupancy $ \\rho = A/C \\in [0,1]$.\n",
    "\n",
    "---\n",
    "\n",
    "### 1) Aggregate to match totals and per-minute rates\n",
    "**Totals across both teams:**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathrm{xG}_{\\mathrm{tot}}      &= \\mathrm{xG}_{\\mathrm{H}} + \\mathrm{xG}_{\\mathrm{A}} \\\\\n",
    "\\mathrm{SoT}_{\\mathrm{tot}}     &= \\mathrm{SoT}_{\\mathrm{H}} + \\mathrm{SoT}_{\\mathrm{A}} \\\\\n",
    "\\mathrm{BigCh}_{\\mathrm{tot}}   &= \\mathrm{BigCh}_{\\mathrm{H}} + \\mathrm{BigCh}_{\\mathrm{A}} \\\\\n",
    "\\mathrm{Corners}_{\\mathrm{tot}} &= \\mathrm{Corners}_{\\mathrm{H}} + \\mathrm{Corners}_{\\mathrm{A}} \\\\\n",
    "\\mathrm{ToB}_{\\mathrm{tot}}     &= \\mathrm{ToB}_{\\mathrm{H}} + \\mathrm{ToB}_{\\mathrm{A}} \\quad (\\text{or } \\mathrm{SiB}_{\\mathrm{H}}+\\mathrm{SiB}_{\\mathrm{A}} \\text{ if ToB unavailable})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Per-minute features (match-level):**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "xg_{\\mathrm{pm}}      &= \\frac{\\mathrm{xG}_{\\mathrm{tot}}}{M} \\\\\n",
    "sot_{\\mathrm{pm}}     &= \\frac{\\mathrm{SoT}_{\\mathrm{tot}}}{M} \\\\\n",
    "big_{\\mathrm{pm}}     &= \\frac{\\mathrm{BigCh}_{\\mathrm{tot}}}{M} \\\\\n",
    "corn_{\\mathrm{pm}}    &= \\frac{\\mathrm{Corners}_{\\mathrm{tot}}}{M} \\\\\n",
    "tob_{\\mathrm{pm}}     &= \\frac{\\mathrm{ToB}_{\\mathrm{tot}}}{M} \\quad \\text{(or } \\frac{\\mathrm{SiB}_{\\mathrm{tot}}}{M}\\text{)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Attendance occupancy (match-level):\n",
    "$$\n",
    "\\rho \\;=\\; \\frac{A}{C}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Season standardization (z-scores)\n",
    "Compute means $\\mu_{\\bullet}$ and standard deviations $\\sigma_{\\bullet}$ over **all matches in the same league & season**. Then:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z_{xg}   &= \\frac{xg_{\\mathrm{pm}} - \\mu_{xg}}{\\sigma_{xg}} \\,,\\quad\n",
    "z_{sot}  &= \\frac{sot_{\\mathrm{pm}} - \\mu_{sot}}{\\sigma_{sot}} \\,,\\quad\n",
    "z_{big}  &= \\frac{big_{\\mathrm{pm}} - \\mu_{big}}{\\sigma_{big}} \\,,\\\\[4pt]\n",
    "z_{corn} &= \\frac{corn_{\\mathrm{pm}} - \\mu_{corn}}{\\sigma_{corn}} \\,,\\quad\n",
    "z_{tob}  &= \\frac{tob_{\\mathrm{pm}} - \\mu_{tob}}{\\sigma_{tob}} \\,,\\quad\n",
    "z_{\\rho} &= \\frac{\\rho - \\mu_{\\rho}}{\\sigma_{\\rho}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 3) Core + attendance boost → raw score\n",
    "**Default component weights (unnormalized):**\n",
    "$$\n",
    "w_{xg}=0.50,\\quad w_{sot}=0.20,\\quad w_{big}=0.10,\\quad w_{corn}=0.10,\\quad w_{tob}=0.10\n",
    "$$\n",
    "\n",
    "If any component is missing (e.g., $tob_{\\mathrm{pm}}$), renormalize weights:\n",
    "$$\n",
    "\\alpha_i \\;=\\; \\frac{w_i}{\\sum_{j \\in \\mathcal{S}} w_j}\\quad\\text{for } i\\in\\mathcal{S}\\ (\\mathcal{S}=\\text{available components})\n",
    "$$\n",
    "\n",
    "**Core (danger + pace):**\n",
    "$$\n",
    "\\mathrm{core} \\;=\\; \\sum_{i\\in\\mathcal{S}} \\alpha_i\\, z_i\n",
    "$$\n",
    "(where $z_i \\in \\{z_{xg}, z_{sot}, z_{big}, z_{corn}, z_{tob}\\}$ as available)\n",
    "\n",
    "**Attendance boost (atmosphere):**\n",
    "$$\n",
    "\\mathrm{boost} \\;=\\; \\operatorname{clip}\\!\\left(\\beta \\, z_{\\rho},\\; -0.30,\\; 0.30\\right),\\quad \\beta = 0.15\n",
    "$$\n",
    "\n",
    "**Raw score:**\n",
    "$$\n",
    "\\mathrm{raw} \\;=\\; \\mathrm{core} \\;+\\; \\mathrm{boost}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 4) Final 0–100 index scaling\n",
    "Let $\\mu_{\\mathrm{raw}}, \\sigma_{\\mathrm{raw}}$ be the season mean and std of $\\mathrm{raw}$. Define:\n",
    "$$\n",
    "z_{\\mathrm{raw}} \\;=\\; \\frac{\\mathrm{raw}-\\mu_{\\mathrm{raw}}}{\\sigma_{\\mathrm{raw}}}\n",
    "$$\n",
    "$$\n",
    "\\boxed{\\ \\mathrm{SLS\\!-\\!F^+} \\;=\\; \\operatorname{clip}\\!\\left(50 \\;+\\; 15\\, z_{\\mathrm{raw}},\\; 0,\\; 100\\right)\\ }\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Fields to extract from the match JSON (for **label** computation)\n",
    "\n",
    "- Team stats (Period = “All”, per team):  \n",
    "  $\\mathrm{xG}_t$, $\\mathrm{SoT}_t$, $\\mathrm{BigCh}_t$, $\\mathrm{Corners}_t$  \n",
    "  *(Optional)* $\\mathrm{ToB}_t$ (touches in opposition box). If absent, use $\\mathrm{SiB}_t$ (shots inside box) from shot events.\n",
    "\n",
    "- Match timing: $\\Delta_{45}$, $\\Delta_{90}$ (added time at 45′ and 90′) to build $M$.\n",
    "\n",
    "- Stadium & attendance: $A$ (attendance), $C$ (capacity) to build $\\rho$.\n",
    "\n",
    "---\n",
    "\n",
    "### Features we will also compute (from multiple match JSONs) for **modeling SLS-F+ pre-match**\n",
    "\n",
    "For each team, over rolling last $N$ matches (e.g., $N{=}5$), with home/away splits as needed:\n",
    "\n",
    "- **Attacking form per 90:**  \n",
    "  $\\overline{\\mathrm{xG}}_{90}$, $\\overline{\\mathrm{SoT}}_{90}$, $\\overline{\\mathrm{BigCh}}_{90}$, $\\overline{\\mathrm{Corners}}_{90}$  \n",
    "  *(Optional)* $\\overline{\\mathrm{ToB}}_{90}$ or $\\overline{\\mathrm{SiB}}_{90}$\n",
    "\n",
    "- **Defensive concessions per 90:**  \n",
    "  $\\overline{\\mathrm{xGA}}_{90}$ (opponent xG against), $\\overline{\\mathrm{SoT\\_against}}_{90}$, $\\overline{\\mathrm{BigCh\\_against}}_{90}$\n",
    "\n",
    "- **Context:**  \n",
    "  Home flag; Days rest since last match (from match dates);  \n",
    "  **Occupancy prior:** average $\\rho$ in recent home games.\n",
    "\n",
    "These features are derived by repeating the label-side extractions across prior match JSONs and averaging per 90. They are the primary inputs for a pre-match predictor of $\\mathrm{SLS\\!-\\!F^+}$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0690bf",
   "metadata": {},
   "source": [
    "### Step 1: Load Match Index and Initialize Data Structures\n",
    "\n",
    "First, we load the index.json file which lists all matches grouped by round (matchweek). This index provides each match’s ID, teams, and the relative path to its detailed JSON file. We will iterate through these rounds and matches to collect data.\n",
    "\n",
    "### Step 2: Extract Match Metrics from JSON\n",
    "\n",
    "For each match, we extract the required inputs for SLS-F+ as specified:\n",
    "\n",
    "- Attendance and Stadium Capacity – from content.matchFacts.infoBox (to compute occupancy).\n",
    "\n",
    "- Added time minutes – from events of type \"AddedTime\" at 45′ and 90′ (to compute total match minutes).\n",
    "\n",
    "- Team stats (full match, “All” period) – from content.stats.Periods.All.stats:\n",
    "\n",
    "- Expected Goals (expected_goals) for home and away.\n",
    "\n",
    "- Total shots (total_shots) for home and away.\n",
    "\n",
    "- Shots on target (ShotsOnTarget) for home and away.\n",
    "\n",
    "- Big chances (big_chance) for home and away.\n",
    "\n",
    "- Corners (corners) for home and away.\n",
    "\n",
    "- Touches in opposition box – team totals. If a team-level stat for this exists in the JSON (key touches_opp_box), we’ll use it. Otherwise, we would sum player stats from the \"Attack\" section (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8116758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import json, os\n",
    "import math\n",
    "import pandas as pd\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1dc4489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the index of matches (schedule for the season)\n",
    "index_path = \"24-25_PL_Data_raw/index.json\"  # path to the index file (adjust if needed)\n",
    "with open(index_path, 'r') as f:\n",
    "    schedule = json.load(f)\n",
    "\n",
    "# Prepare a list to collect per-match data\n",
    "match_data_list = []\n",
    "\n",
    "# Loop through each round in the schedule\n",
    "for round_info in schedule:\n",
    "    round_num = round_info[\"round\"]\n",
    "    for match_info in round_info[\"matches\"]:\n",
    "        match_id   = match_info[\"matchId\"]\n",
    "        home_team  = match_info[\"home\"]\n",
    "        away_team  = match_info[\"away\"]\n",
    "        json_rel   = match_info[\"jsonPath\"]         # e.g., \"round_0/4506263_matchDetails_Manchester_United-vs-Fulham.json\"\n",
    "        # Construct absolute path to the match JSON file\n",
    "        base_dir   = os.path.dirname(index_path)    # base directory of index.json\n",
    "        match_path = os.path.join(base_dir, json_rel)\n",
    "        if not os.path.exists(match_path):\n",
    "            # Fallback: if the file is not found in the expected subfolder, try base directory\n",
    "            match_path = os.path.join(base_dir, os.path.basename(json_rel))\n",
    "        if not os.path.exists(match_path):\n",
    "            # If file still not found, skip this match (data might be missing)\n",
    "            continue\n",
    "\n",
    "        # --- Load the match JSON data ---\n",
    "        with open(match_path, 'r') as f:\n",
    "            match_json = json.load(f)\n",
    "        \n",
    "            # --- Extract attendance and capacity for occupancy ---\n",
    "            info_box   = match_json.get(\"content\", {}).get(\"matchFacts\", {}).get(\"infoBox\", {})\n",
    "            attendance = info_box.get(\"Attendance\")\n",
    "            capacity   = None\n",
    "            if \"Stadium\" in info_box:\n",
    "                capacity = info_box[\"Stadium\"].get(\"capacity\")\n",
    "            # Compute occupancy (fraction of stadium filled)\n",
    "            if attendance is not None and capacity and capacity > 0:\n",
    "                occ = attendance / capacity\n",
    "            else:\n",
    "                occ = None\n",
    "    \n",
    "            # --- Determine total match minutes (90 + added time) ---\n",
    "            match_minutes = 90\n",
    "            # Find events of type \"AddedTime\" at 45' and 90'\n",
    "            def find_added_times(obj):\n",
    "                results = []\n",
    "                if isinstance(obj, dict):\n",
    "                    if obj.get(\"type\") == \"AddedTime\" and \"minutesAddedInput\" in obj:\n",
    "                        results.append(obj)\n",
    "                    for value in obj.values():\n",
    "                        results += find_added_times(value)\n",
    "                elif isinstance(obj, list):\n",
    "                    for item in obj:\n",
    "                        results += find_added_times(item)\n",
    "                return results\n",
    "    \n",
    "            added_time_events = find_added_times(match_json.get(\"header\", {}))\n",
    "            # Sum all minutes added in first half (time == 45) and second half (time == 90)\n",
    "            added_first_half  = sum(ev.get(\"minutesAddedInput\", 0) or 0 for ev in added_time_events if ev.get(\"time\") == 45)\n",
    "            added_second_half = sum(ev.get(\"minutesAddedInput\", 0) or 0 for ev in added_time_events if ev.get(\"time\") == 90)\n",
    "            match_minutes     = 90 + added_first_half + added_second_half\n",
    "            if match_minutes < 80:\n",
    "                # If match duration is unrealistically low (e.g., abandonment), default to 90\n",
    "                match_minutes = 90\n",
    "    \n",
    "            # --- Extract team aggregate stats from \"Top stats\" section ---\n",
    "            stats_all   = match_json.get(\"content\", {}).get(\"stats\", {}).get(\"Periods\", {}).get(\"All\", {})\n",
    "            stats_groups = stats_all.get(\"stats\", []) if isinstance(stats_all, dict) else stats_all  # handle dict or list form\n",
    "            # Initialize stat values\n",
    "            xG_home = xG_away = 0.0\n",
    "            shots_home = shots_away = 0\n",
    "            SOT_home = SOT_away = 0\n",
    "            bigch_home = bigch_away = 0\n",
    "            corners_home = corners_away = 0\n",
    "    \n",
    "            # Find the \"Top stats\" group and extract relevant stats\n",
    "            top_stats_group = next((grp for grp in stats_groups if grp.get(\"key\") == \"top_stats\"), None)\n",
    "            if top_stats_group:\n",
    "                for stat_item in top_stats_group.get(\"stats\", []):\n",
    "                    key   = stat_item.get(\"key\")\n",
    "                    values = stat_item.get(\"stats\", [])\n",
    "                    if len(values) < 2:\n",
    "                        continue  # skip if we don't have both home and away values\n",
    "                    home_val, away_val = values[0], values[1]\n",
    "                    # Convert values to numeric (floats/ints). Some values may be strings (e.g., \"2.43\").\n",
    "                    def to_number(v):\n",
    "                        if v is None:\n",
    "                            return 0\n",
    "                        if isinstance(v, (int, float)):\n",
    "                            return float(v)\n",
    "                        if isinstance(v, str):\n",
    "                            s = v.strip()\n",
    "                            if s == \"\":\n",
    "                                return 0\n",
    "                            # If the string includes a percentage or other text (unlikely in these stats), extract the numeric part\n",
    "                            try:\n",
    "                                return float(s)\n",
    "                            except ValueError:\n",
    "                                # If string has a format like \"408 (85%)\", take the first part before space or parentheses\n",
    "                                import re\n",
    "                                num_str = re.match(r'[\\d\\.]+', s)  # match leading numeric part\n",
    "                                return float(num_str.group()) if num_str else 0\n",
    "                        return 0\n",
    "    \n",
    "                    hv = to_number(home_val)\n",
    "                    av = to_number(away_val)\n",
    "                    if key == \"expected_goals\":\n",
    "                        xG_home, xG_away = hv, av\n",
    "                    elif key == \"total_shots\":\n",
    "                        shots_home, shots_away = int(hv), int(av)\n",
    "                    elif key == \"ShotsOnTarget\":\n",
    "                        SOT_home, SOT_away = int(hv), int(av)\n",
    "                    elif key == \"big_chance\":\n",
    "                        bigch_home, bigch_away = int(hv), int(av)\n",
    "                    elif key == \"corners\":\n",
    "                        corners_home, corners_away = int(hv), int(av)\n",
    "    \n",
    "            # --- Extract touches in opposition box (if available) ---\n",
    "            touches_opp_box_home = touches_opp_box_away = None\n",
    "            for group in stats_groups:\n",
    "                for stat_item in group.get(\"stats\", []):\n",
    "                    if stat_item.get(\"key\") == \"touches_opp_box\":\n",
    "                        vals = stat_item.get(\"stats\", [])\n",
    "                        if len(vals) >= 2:\n",
    "                            try:\n",
    "                                touches_opp_box_home = int(vals[0])\n",
    "                                touches_opp_box_away = int(vals[1])\n",
    "                            except ValueError:\n",
    "                                touches_opp_box_home = float(vals[0])\n",
    "                                touches_opp_box_away = float(vals[1])\n",
    "            # If touches in opp. box is not directly provided, we could sum player stats (not shown here for brevity).\n",
    "            if touches_opp_box_home is None or touches_opp_box_away is None:\n",
    "                touches_opp_box_home = touches_opp_box_home or 0\n",
    "                touches_opp_box_away = touches_opp_box_away or 0\n",
    "    \n",
    "            # --- Compute match totals and per-minute rates ---\n",
    "            xG_total     = xG_home + xG_away\n",
    "            shots_total  = shots_home + shots_away\n",
    "            SOT_total    = SOT_home + SOT_away\n",
    "            bigch_total  = bigch_home + bigch_away\n",
    "            corners_total= corners_home + corners_away\n",
    "            tob_total    = None if (touches_opp_box_home is None or touches_opp_box_away is None) else (touches_opp_box_home + touches_opp_box_away)\n",
    "    \n",
    "            # Rates per minute of match (to normalize pace across different match lengths)\n",
    "            minutes = match_minutes if match_minutes > 0 else 90\n",
    "            xG_per_min       = xG_total / minutes\n",
    "            shots_per_min    = shots_total / minutes\n",
    "            SOT_per_min      = SOT_total / minutes\n",
    "            bigch_per_min    = bigch_total / minutes\n",
    "            corners_per_min  = corners_total / minutes\n",
    "            tob_per_min      = tob_total / minutes if tob_total is not None else None\n",
    "    \n",
    "            # Store all collected metrics for this match\n",
    "            match_data_list.append({\n",
    "                \"Round\": round_num,\n",
    "                \"HomeTeam\": home_team,\n",
    "                \"AwayTeam\": away_team,\n",
    "                \"Attendance\": attendance,\n",
    "                \"Capacity\": capacity,\n",
    "                \"Occupancy\": occ,\n",
    "                \"MatchMinutes\": minutes,\n",
    "                \"xG_home\": xG_home, \"xG_away\": xG_away,\n",
    "                \"Shots_home\": shots_home, \"Shots_away\": shots_away,\n",
    "                \"ShotsOnTarget_home\": SOT_home, \"ShotsOnTarget_away\": SOT_away,\n",
    "                \"BigChances_home\": bigch_home, \"BigChances_away\": bigch_away,\n",
    "                \"Corners_home\": corners_home, \"Corners_away\": corners_away,\n",
    "                \"TouchesOppBox_home\": touches_opp_box_home, \"TouchesOppBox_away\": touches_opp_box_away,\n",
    "                \"xG_per_min\": xG_per_min,\n",
    "                \"Shots_per_min\": shots_per_min,\n",
    "                \"ShotsOnTarget_per_min\": SOT_per_min,\n",
    "                \"BigChances_per_min\": bigch_per_min,\n",
    "                \"Corners_per_min\": corners_per_min,\n",
    "                \"TouchesOppBox_per_min\": tob_per_min\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e81b4a0",
   "metadata": {},
   "source": [
    "### Step 3: Standardize Features (League-wide Z-Scores)\n",
    "SLS-F+ uses z-scores to normalize each feature relative to the distribution of that feature across the league and season. Now that we have all matches’ data in match_data_list, we calculate the mean and standard deviation for each per-minute feature and for occupancy across all matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47b01793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute league-wide mean (μ) and std deviation (σ) for each per-minute feature\n",
    "features = [\"xG_per_min\", \"ShotsOnTarget_per_min\", \"Shots_per_min\", \"BigChances_per_min\", \"Corners_per_min\"]\n",
    "if any(m[\"TouchesOppBox_per_min\"] is not None for m in match_data_list):\n",
    "    features.append(\"TouchesOppBox_per_min\")\n",
    "\n",
    "feature_means = {}\n",
    "feature_stds  = {}\n",
    "for feat in features:\n",
    "    # Gather all non-null values for this feature across matches\n",
    "    vals = [m[feat] for m in match_data_list if m[feat] is not None]\n",
    "    if not vals:\n",
    "        feature_means[feat] = 0.0\n",
    "        feature_stds[feat]  = 0.0\n",
    "    else:\n",
    "        # Calculate mean\n",
    "        mu = sum(vals) / len(vals)\n",
    "        # Calculate population std (using N, not N-1, since we consider full season data)\n",
    "        variance = sum((x - mu)**2 for x in vals) / len(vals)\n",
    "        sigma    = math.sqrt(variance)\n",
    "        feature_means[feat] = mu\n",
    "        feature_stds[feat]  = sigma\n",
    "\n",
    "# Compute league-wide mean and std for occupancy as well\n",
    "occ_vals = [m[\"Occupancy\"] for m in match_data_list if m[\"Occupancy\"] is not None]\n",
    "mu_occ   = sum(occ_vals)/len(occ_vals) if occ_vals else 0.0\n",
    "var_occ  = sum((x - mu_occ)**2 for x in occ_vals)/len(occ_vals) if occ_vals else 0.0\n",
    "sigma_occ= math.sqrt(var_occ) if occ_vals else 0.0\n",
    "\n",
    "# Add z-scores for each match in our data list\n",
    "for m in match_data_list:\n",
    "    # Z-score for each feature f: z_f = (f_value - μ_f) / σ_f\n",
    "    for feat in features:\n",
    "        val = m[feat]\n",
    "        mu  = feature_means.get(feat, 0.0)\n",
    "        sigma = feature_stds.get(feat, 0.0)\n",
    "        if sigma and val is not None:\n",
    "            m[f\"z_{feat}\"] = (val - mu) / (sigma + 1e-9)  # small epsilon to avoid division by zero\n",
    "        else:\n",
    "            m[f\"z_{feat}\"] = 0.0  # if missing or zero std, set z-score to 0 (average)\n",
    "    # Z-score for occupancy\n",
    "    if m[\"Occupancy\"] is not None and sigma_occ:\n",
    "        m[\"z_occ\"] = (m[\"Occupancy\"] - mu_occ) / (sigma_occ + 1e-9)\n",
    "    else:\n",
    "        m[\"z_occ\"] = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16ab7d3",
   "metadata": {},
   "source": [
    "### Step 4: Calculate SLS-F+ (Core Blend + Attendance Boost)\n",
    "\n",
    "With all features standardized, we calculate the core liveliness component and the crowd boost for each match, then combine them into the raw SLS-F+ score and scale it to a 0–100 range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a5341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature weights for the core liveliness score\n",
    "use_tob = \"TouchesOppBox_per_min\" in features  # whether touches in opp. box data is available\n",
    "if use_tob:\n",
    "    core_weights = {\n",
    "        \"xG_per_min\": 0.50,\n",
    "        \"ShotsOnTarget_per_min\": 0.20,\n",
    "        \"BigChances_per_min\": 0.10,\n",
    "        \"Corners_per_min\": 0.10,\n",
    "        \"TouchesOppBox_per_min\": 0.10\n",
    "    }\n",
    "else:\n",
    "    # If ToB is not available, re-normalize weights (sum to 1)\n",
    "    core_weights = {\n",
    "        \"xG_per_min\": 0.56,\n",
    "        \"ShotsOnTarget_per_min\": 0.22,\n",
    "        \"BigChances_per_min\": 0.11,\n",
    "        \"Corners_per_min\": 0.11\n",
    "        # (Optionally could include Shots_per_min at a small weight if ToB is absent)\n",
    "    }\n",
    "\n",
    "β = 0.15  # weight factor for attendance boost\n",
    "\n",
    "for m in match_data_list:\n",
    "    # Core component: weighted sum of feature z-scores\n",
    "    core_score = 0.0\n",
    "    for feat, w in core_weights.items():\n",
    "        core_score += w * m.get(f\"z_{feat}\", 0.0)\n",
    "    m[\"core\"] = core_score\n",
    "\n",
    "    # Attendance boost: β * z_occ, clamped to [-0.30, +0.30]\n",
    "    boost = β * m[\"z_occ\"]\n",
    "    if boost > 0.30: \n",
    "        boost = 0.30\n",
    "    if boost < -0.30:\n",
    "        boost = -0.30\n",
    "    m[\"boost\"] = boost\n",
    "\n",
    "    # Raw combined score (before scaling)\n",
    "    m[\"raw_score\"] = core_score + boost\n",
    "\n",
    "# Compute mean and std of the raw combined scores across all matches (for final scaling)\n",
    "raw_values = [m[\"raw_score\"] for m in match_data_list]\n",
    "mu_raw  = sum(raw_values)/len(raw_values) if raw_values else 0.0\n",
    "var_raw = sum((x - mu_raw)**2 for x in raw_values)/len(raw_values) if raw_values else 0.0\n",
    "sigma_raw = math.sqrt(var_raw) if raw_values else 0.0\n",
    "\n",
    "# Scale raw scores to 0–100 range with mean ~50 and std dev ~15\n",
    "for m in match_data_list:\n",
    "    if sigma_raw:\n",
    "        z_raw = (m[\"raw_score\"] - mu_raw) / (sigma_raw + 1e-9)\n",
    "    else:\n",
    "        z_raw = 0.0\n",
    "    m[\"z_raw\"]   = z_raw\n",
    "    # Linear mapping: mean->50, 1 std->15 points\n",
    "    SLS = 50 + 15 * z_raw\n",
    "    # Clip to [0, 100]\n",
    "    if SLS < 0:   SLS = 0.0\n",
    "    if SLS > 100: SLS = 100.0\n",
    "    m[\"SLS_Fplus\"] = SLS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b23265b",
   "metadata": {},
   "source": [
    "### Step 5: Save Results to CSV Files\n",
    "\n",
    "With all matches processed, we can organize the results into tables. We will create one CSV file per round (matchweek), as well as an aggregated file for all rounds combined. Each table will have one row per match with the following columns:\n",
    "\n",
    "- Round (matchweek number, 0-indexed in our data if round 0 = week 1).\n",
    "\n",
    "- HomeTeam, AwayTeam.\n",
    "\n",
    "- Occupancy (attendance fraction, e.g., 0.96 meaning 96% of stadium filled).\n",
    "\n",
    "- xG_home, xG_away.\n",
    "\n",
    "- Shots_home, Shots_away.\n",
    "\n",
    "- ShotsOnTarget_home, ShotsOnTarget_away.\n",
    "\n",
    "- BigChances_home, BigChances_away.\n",
    "\n",
    "- Corners_home, Corners_away.\n",
    "\n",
    "- TouchesOppBox_home, TouchesOppBox_away (total touches in opposition box for each team).\n",
    "\n",
    "- SLS_Fplus (the computed liveliness score for the match, 0–100).\n",
    "\n",
    "Let's convert our list of match dictionaries into a pandas DataFrame for convenient output, then save the CSVs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dfbfa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the collected data into a DataFrame\n",
    "df = pd.DataFrame(match_data_list)\n",
    "\n",
    "# Select and order the columns for output\n",
    "columns = [\n",
    "    \"Round\", \"HomeTeam\", \"AwayTeam\", \"Occupancy\",\n",
    "    \"xG_home\", \"xG_away\", \"Shots_home\", \"Shots_away\",\n",
    "    \"ShotsOnTarget_home\", \"ShotsOnTarget_away\",\n",
    "    \"BigChances_home\", \"BigChances_away\",\n",
    "    \"Corners_home\", \"Corners_away\"\n",
    "]\n",
    "# Include touches in box columns if available in data\n",
    "if any(df[\"TouchesOppBox_home\"].notna()):\n",
    "    columns += [\"TouchesOppBox_home\", \"TouchesOppBox_away\"]\n",
    "# Append the target score\n",
    "columns.append(\"SLS_Fplus\")\n",
    "\n",
    "df_out = df[columns]\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"tables\", exist_ok=True)\n",
    "\n",
    "# Save one CSV per round\n",
    "for rnd, group in df_out.groupby(\"Round\"):\n",
    "    output_path = f\"tables/round_{rnd}.csv\"\n",
    "    # Drop the Round column in individual round files (since it's obvious from filename)\n",
    "    group.drop(columns=[\"Round\"], inplace=False).to_csv(output_path, index=False)\n",
    "\n",
    "# Also save a combined file for all rounds (with Round included)\n",
    "df_out.to_csv(\"tables/all_rounds.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3700985",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "To predict the Spectator Liveliness Score (SLS-F+) before a match, we need to derive features from each team’s recent performance without any data leakage. We will compute per-team features based on the last $N=5$ matches (using fewer if a team has played less) as follows:\n",
    "\n",
    "Attacking form (per 90 minutes): Average Expected Goals (xG), Shots on Target (SoT), Big Chances, Corners, and (optionally) Touches in Opposition Box over the last 5 matches. These features capture a team’s offensive output rate.\n",
    "\n",
    "Defensive form (per 90 minutes): Average xG Against (opponent’s xG), Shots on Target against, and Big Chances against over the last 5 matches. These reflect how much the team concedes chances.\n",
    "\n",
    "Contextual factors:\n",
    "\n",
    "- A binary home-field indicator (implicitly handled by having separate home/away feature sets per match).\n",
    "\n",
    "- Days of rest since each team’s previous match.\n",
    "\n",
    "- Occupancy prior: the average stadium occupancy (fraction of capacity filled) in the home team’s recent home games, which serves as a proxy for crowd atmosphere. (For away teams, this specific feature is not used, since occupancy is tied to home stadiums.)\n",
    "\n",
    "We must ensure these features for a given match are computed only from past matches. For the first few matches of the season when a team has little or no history (less than 3 games), we will use league-average values as a fallback to avoid unreliable small samples. The league averages are computed incrementally from matches that have already been played (e.g. using data from previous rounds), thereby avoiding any future data leakage. This way, early-season matches are essentially treated as between “average” teams until enough data accumulates.\n",
    "\n",
    "Additionally, we can consider including the team identities (HomeTeam and AwayTeam) as categorical features. Incorporating team names (as one-hot encoded or categorical variables) can help the model capture team-specific tendencies and historical home advantage differences. However, this comes at the risk of overfitting to known teams; if our goal is purely within one season and we have enough data, it may be beneficial. In our approach below, we will keep the team names as features (which can later be encoded) so that the model can learn, for example, that certain teams’ matches tend to be more lively, or that certain teams perform better at home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19c16c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - feature_tables/match_features_wide.csv\n",
      " - feature_tables/match_features_long.csv\n",
      "Columns in wide file:\n",
      "['Round', 'HomeTeam', 'AwayTeam', 'Home_days_rest', 'Away_days_rest', 'DaysRestDiff', 'Home_occ_prior', 'LeagueAvg_xG_perMatch_sofar', 'LeagueAvg_Corners_perMatch_sofar', 'HomeFlag', 'Home_xG_att_90', 'Home_SoT_att_90', 'Home_BigCh_att_90', 'Home_Corn_att_90', 'Home_ToB_att_90', 'Home_xGA_def_90', 'Home_SoT_agst_90', 'Home_BigCh_agst_90', 'Away_xG_att_90', 'Away_SoT_att_90', 'Away_BigCh_att_90', 'Away_Corn_att_90', 'Away_ToB_att_90', 'Away_xGA_def_90', 'Away_SoT_agst_90', 'Away_BigCh_agst_90', 'Home_AttackVsDefense', 'Away_AttackVsDefense', 'TempoSum', 'SoTSum', 'SLS_Fplus']\n",
      "Columns in long file:\n",
      "['Round', 'Team', 'Role', 'Opponent', 'xG_att_90', 'SoT_att_90', 'BigCh_att_90', 'Corn_att_90', 'ToB_att_90', 'xGA_def_90', 'SoT_agst_90', 'BigCh_agst_90', 'Days_rest', 'Occ_prior', 'AttackVsDefense', 'TempoSum', 'SoTSum', 'LeagueAvg_xG_perMatch_sofar', 'LeagueAvg_Corners_perMatch_sofar', 'SLS_Fplus']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "############################################################\n",
    "# Config / helpers\n",
    "############################################################\n",
    "\n",
    "INDEX_PATH = \"24-25_PL_Data_raw/index.json\"\n",
    "SLS_TABLE_PATH = \"tables/all_rounds.csv\"\n",
    "OUT_DIR = \"feature_tables\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Baseline priors for first ~2 rounds before we have any history at all.\n",
    "# These are just safe starting priors so model doesn't blow up early season.\n",
    "BASELINE_PRIOR = {\n",
    "    \"xG_per90\": 1.3,      # typical team xG per 90\n",
    "    \"SoT_per90\": 3.5,     # shots on target per team per match\n",
    "    \"BigCh_per90\": 2.0,   # big chances\n",
    "    \"Corn_per90\": 5.0,    # corners\n",
    "    \"ToB_per90\": 24.0,    # touches in opp box\n",
    "    \"occ\": 0.95,          # 95% full, rough EPL vibe\n",
    "    \"league_xG_match\": 2.6,\n",
    "    \"league_corners_match\": 10.0\n",
    "}\n",
    "\n",
    "def safe_iso_to_dt(s):\n",
    "    \"\"\"Convert various FotMob-style timestamps -> datetime or None.\"\"\"\n",
    "    if s is None:\n",
    "        return None\n",
    "    # common forms: \"2024-08-10T19:00:00.000Z\", \"2024-08-10T19:00:00Z\"\n",
    "    s = s.replace(\"Z\",\"\")\n",
    "    try:\n",
    "        return datetime.fromisoformat(s)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def safe_float(x):\n",
    "    \"\"\"Convert string/int/None -> float 0.0 fallback.\"\"\"\n",
    "    if x is None:\n",
    "        return 0.0\n",
    "    if isinstance(x,(int,float)):\n",
    "        return float(x)\n",
    "    try:\n",
    "        return float(str(x).split()[0])\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def per90(sum_stat, sum_mins):\n",
    "    \"\"\"Convert raw total over N minutes to per-90 rate.\"\"\"\n",
    "    if sum_mins is None or sum_mins <= 0:\n",
    "        return 0.0\n",
    "    return (sum_stat / sum_mins) * 90.0\n",
    "\n",
    "############################################################\n",
    "# Core rolling feature builder\n",
    "############################################################\n",
    "\n",
    "# We'll keep:\n",
    "# - team_history[team] = list of dicts, one per past match\n",
    "# - global aggregates for league context \"so far\"\n",
    "team_history = {}\n",
    "\n",
    "global_occ_sum = 0.0\n",
    "global_occ_n = 0\n",
    "\n",
    "# For per-team priors when not enough history:\n",
    "global_team_minutes = 0.0\n",
    "global_xG_sum = 0.0\n",
    "global_SoT_sum = 0.0\n",
    "global_BigCh_sum = 0.0\n",
    "global_Corn_sum = 0.0\n",
    "global_ToB_sum = 0.0\n",
    "\n",
    "# For league-wide context features\n",
    "global_match_count = 0\n",
    "global_match_xG_sum = 0.0\n",
    "global_match_corners_sum = 0.0\n",
    "\n",
    "feature_rows = []\n",
    "\n",
    "# Load index (season schedule grouped by round)\n",
    "with open(INDEX_PATH, \"r\") as f:\n",
    "    schedule = json.load(f)\n",
    "\n",
    "# Loop rounds in chronological order\n",
    "for round_info in schedule:\n",
    "    rnd = round_info[\"round\"]\n",
    "\n",
    "    # First pass: read raw match JSONs for the round\n",
    "    round_matches = []\n",
    "    for m in round_info[\"matches\"]:\n",
    "        match_id = m[\"matchId\"]\n",
    "        home_team = m[\"home\"]\n",
    "        away_team = m[\"away\"]\n",
    "\n",
    "        # resolve path to the match JSON\n",
    "        # index.json may say e.g. \"round_0/4506...json\"\n",
    "        guess_path = os.path.join(os.path.dirname(INDEX_PATH), m[\"jsonPath\"])\n",
    "        if not os.path.exists(guess_path):\n",
    "            # fallback: just take basename\n",
    "            guess_path = os.path.join(os.path.dirname(INDEX_PATH),\n",
    "                                      os.path.basename(m[\"jsonPath\"]))\n",
    "        if not os.path.exists(guess_path):\n",
    "            # if file not found, skip\n",
    "            continue\n",
    "\n",
    "        with open(guess_path, \"r\") as jf:\n",
    "            match_json = json.load(jf)\n",
    "\n",
    "        # Match datetime (used for rest-days calc)\n",
    "        match_date = None\n",
    "        # Some FotMob exports contain this under general.matchTimeUTCDate\n",
    "        match_date = safe_iso_to_dt(\n",
    "            match_json.get(\"general\",{}).get(\"matchTimeUTCDate\")\n",
    "        )\n",
    "\n",
    "        # Attendance / capacity -> occupancy\n",
    "        info_box = (\n",
    "            match_json.get(\"content\",{})\n",
    "                      .get(\"matchFacts\",{})\n",
    "                      .get(\"infoBox\",{})\n",
    "        )\n",
    "        attendance = info_box.get(\"Attendance\")\n",
    "        stadium = info_box.get(\"Stadium\",{})\n",
    "        capacity = stadium.get(\"capacity\")\n",
    "        attendance = attendance if isinstance(attendance,int) else safe_float(attendance)\n",
    "        capacity = capacity if isinstance(capacity,int) else safe_float(capacity)\n",
    "        occupancy = None\n",
    "        if attendance and capacity and capacity > 0:\n",
    "            occupancy = attendance / capacity\n",
    "\n",
    "        # Approximate match minutes\n",
    "        # If we don't have stoppage-time detail, assume ~95 total\n",
    "        match_minutes = 95.0\n",
    "\n",
    "        # Extract team stats from \"Periods -> All -> stats\"\n",
    "        # We want: xG, ShotsOnTarget, big_chance, corners, touches_opp_box\n",
    "        xG_home = xG_away = 0.0\n",
    "        SoT_home = SoT_away = 0.0\n",
    "        BigCh_home = BigCh_away = 0.0\n",
    "        Corn_home = Corn_away = 0.0\n",
    "        ToB_home = ToB_away = 0.0\n",
    "\n",
    "        periods_all = (\n",
    "            match_json.get(\"content\",{})\n",
    "                      .get(\"stats\",{})\n",
    "                      .get(\"Periods\",{})\n",
    "                      .get(\"All\",{})\n",
    "        )\n",
    "        stats_groups = periods_all.get(\"stats\", [])\n",
    "\n",
    "        # Pull top_stats first\n",
    "        top_stats_group = None\n",
    "        for grp in stats_groups:\n",
    "            if grp.get(\"key\") == \"top_stats\":\n",
    "                top_stats_group = grp\n",
    "                break\n",
    "        if top_stats_group:\n",
    "            for stat_item in top_stats_group.get(\"stats\",[]):\n",
    "                key = stat_item.get(\"key\")\n",
    "                vals = stat_item.get(\"stats\",[])\n",
    "                if len(vals) < 2:\n",
    "                    continue\n",
    "                hv = safe_float(vals[0])\n",
    "                av = safe_float(vals[1])\n",
    "\n",
    "                if key == \"expected_goals\":\n",
    "                    xG_home, xG_away = hv, av\n",
    "                elif key == \"ShotsOnTarget\":\n",
    "                    SoT_home, SoT_away = hv, av\n",
    "                elif key == \"big_chance\":\n",
    "                    BigCh_home, BigCh_away = hv, av\n",
    "                elif key == \"corners\":\n",
    "                    Corn_home, Corn_away = hv, av\n",
    "\n",
    "        # Touches in opposition box might live in a different stat group\n",
    "        for grp in stats_groups:\n",
    "            for stat_item in grp.get(\"stats\",[]):\n",
    "                if stat_item.get(\"key\") == \"touches_opp_box\":\n",
    "                    vals = stat_item.get(\"stats\",[])\n",
    "                    if len(vals) >= 2:\n",
    "                        ToB_home = safe_float(vals[0])\n",
    "                        ToB_away = safe_float(vals[1])\n",
    "\n",
    "        round_matches.append({\n",
    "            \"Round\": rnd,\n",
    "            \"date\": match_date,\n",
    "            \"home_team\": home_team,\n",
    "            \"away_team\": away_team,\n",
    "            \"minutes\": match_minutes,\n",
    "            \"occupancy\": occupancy,\n",
    "            \"xG_home\": xG_home, \"xG_away\": xG_away,\n",
    "            \"SoT_home\": SoT_home, \"SoT_away\": SoT_away,\n",
    "            \"BigCh_home\": BigCh_home, \"BigCh_away\": BigCh_away,\n",
    "            \"Corn_home\": Corn_home, \"Corn_away\": Corn_away,\n",
    "            \"ToB_home\": ToB_home, \"ToB_away\": ToB_away\n",
    "        })\n",
    "\n",
    "    # Second pass: build forward-looking features for each match in this round\n",
    "    for match in round_matches:\n",
    "        home = match[\"home_team\"]\n",
    "        away = match[\"away_team\"]\n",
    "\n",
    "        # init team histories if first time seen\n",
    "        if home not in team_history:\n",
    "            team_history[home] = []\n",
    "        if away not in team_history:\n",
    "            team_history[away] = []\n",
    "\n",
    "        # helper to build per-90 attacking form for N last matches\n",
    "        def build_attacking(team):\n",
    "            hist = team_history[team]\n",
    "            if len(hist) < 3:\n",
    "                # fallback: league-average so far, or baseline if none\n",
    "                if global_team_minutes > 0:\n",
    "                    per_min_xG   = global_xG_sum   / global_team_minutes\n",
    "                    per_min_SoT  = global_SoT_sum  / global_team_minutes\n",
    "                    per_min_BC   = global_BigCh_sum/ global_team_minutes\n",
    "                    per_min_Corn = global_Corn_sum / global_team_minutes\n",
    "                    per_min_ToB  = global_ToB_sum  / global_team_minutes\n",
    "                    return {\n",
    "                        \"xG_att_90\":   per_min_xG*90,\n",
    "                        \"SoT_att_90\":  per_min_SoT*90,\n",
    "                        \"BigCh_att_90\":per_min_BC*90,\n",
    "                        \"Corn_att_90\": per_min_Corn*90,\n",
    "                        \"ToB_att_90\":  per_min_ToB*90\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        \"xG_att_90\":   BASELINE_PRIOR[\"xG_per90\"],\n",
    "                        \"SoT_att_90\":  BASELINE_PRIOR[\"SoT_per90\"],\n",
    "                        \"BigCh_att_90\":BASELINE_PRIOR[\"BigCh_per90\"],\n",
    "                        \"Corn_att_90\": BASELINE_PRIOR[\"Corn_per90\"],\n",
    "                        \"ToB_att_90\":  BASELINE_PRIOR[\"ToB_per90\"]\n",
    "                    }\n",
    "            # else: use last up to 5 games\n",
    "            recent = hist[-5:]\n",
    "            mins_sum = sum(g[\"minutes\"] for g in recent)\n",
    "            return {\n",
    "                \"xG_att_90\":   per90(sum(g[\"xG_for\"]        for g in recent), mins_sum),\n",
    "                \"SoT_att_90\":  per90(sum(g[\"SoT_for\"]       for g in recent), mins_sum),\n",
    "                \"BigCh_att_90\":per90(sum(g[\"BigCh_for\"]     for g in recent), mins_sum),\n",
    "                \"Corn_att_90\": per90(sum(g[\"Corn_for\"]      for g in recent), mins_sum),\n",
    "                \"ToB_att_90\":  per90(sum(g[\"ToB_for\"]       for g in recent), mins_sum)\n",
    "            }\n",
    "\n",
    "        # helper to build defensive concessions form\n",
    "        def build_defensive(team):\n",
    "            hist = team_history[team]\n",
    "            if len(hist) < 3:\n",
    "                if global_team_minutes > 0:\n",
    "                    per_min_xGA   = global_xG_sum   / global_team_minutes\n",
    "                    per_min_SoTA  = global_SoT_sum  / global_team_minutes\n",
    "                    per_min_BCA   = global_BigCh_sum/ global_team_minutes\n",
    "                    return {\n",
    "                        \"xGA_def_90\":    per_min_xGA*90,\n",
    "                        \"SoT_agst_90\":   per_min_SoTA*90,\n",
    "                        \"BigCh_agst_90\": per_min_BCA*90\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        \"xGA_def_90\":    BASELINE_PRIOR[\"xG_per90\"],\n",
    "                        \"SoT_agst_90\":   BASELINE_PRIOR[\"SoT_per90\"],\n",
    "                        \"BigCh_agst_90\": BASELINE_PRIOR[\"BigCh_per90\"]\n",
    "                    }\n",
    "            recent = hist[-5:]\n",
    "            mins_sum = sum(g[\"minutes\"] for g in recent)\n",
    "            return {\n",
    "                \"xGA_def_90\":    per90(sum(g[\"xG_against\"]    for g in recent), mins_sum),\n",
    "                \"SoT_agst_90\":   per90(sum(g[\"SoT_against\"]   for g in recent), mins_sum),\n",
    "                \"BigCh_agst_90\": per90(sum(g[\"BigCh_against\"] for g in recent), mins_sum)\n",
    "            }\n",
    "\n",
    "        # helper to compute days rest\n",
    "        def days_rest(team, match_dt):\n",
    "            hist = team_history[team]\n",
    "            if not hist or match_dt is None or hist[-1][\"date\"] is None:\n",
    "                return 7  # default\n",
    "            delta = match_dt - hist[-1][\"date\"]\n",
    "            return max(delta.days, 0)\n",
    "\n",
    "        # home occupancy prior = mean of last up to 5 home games' occupancy,\n",
    "        # or league avg occupancy so far, or baseline.\n",
    "        def occupancy_prior_home(team):\n",
    "            hist = team_history[team]\n",
    "            home_games = [g[\"occupancy\"] for g in hist\n",
    "                          if g[\"homeAway\"] == \"home\" and g[\"occupancy\"] is not None]\n",
    "            if len(home_games) < 3:\n",
    "                if global_occ_n > 0:\n",
    "                    return global_occ_sum / global_occ_n\n",
    "                return BASELINE_PRIOR[\"occ\"]\n",
    "            recent_home = home_games[-5:]\n",
    "            return sum(recent_home)/len(recent_home)\n",
    "\n",
    "        # league averages so far (for context features)\n",
    "        if global_match_count > 0:\n",
    "            league_xG_sofar = global_match_xG_sum / global_match_count\n",
    "            league_corn_sofar = global_match_corners_sum / global_match_count\n",
    "        else:\n",
    "            league_xG_sofar = BASELINE_PRIOR[\"league_xG_match\"]\n",
    "            league_corn_sofar = BASELINE_PRIOR[\"league_corners_match\"]\n",
    "\n",
    "        # build forms\n",
    "        home_att = build_attacking(home)\n",
    "        away_att = build_attacking(away)\n",
    "        home_def = build_defensive(home)\n",
    "        away_def = build_defensive(away)\n",
    "\n",
    "        home_rest = days_rest(home, match[\"date\"])\n",
    "        away_rest = days_rest(away, match[\"date\"])\n",
    "\n",
    "        occ_prior = occupancy_prior_home(home)\n",
    "\n",
    "        # composite predictors\n",
    "        Home_AttackVsDefense = home_att[\"xG_att_90\"] + away_def[\"xGA_def_90\"]\n",
    "        Away_AttackVsDefense = away_att[\"xG_att_90\"] + home_def[\"xGA_def_90\"]\n",
    "        TempoSum = home_att[\"Corn_att_90\"] + away_att[\"Corn_att_90\"]\n",
    "        SoTSum = home_att[\"SoT_att_90\"] + away_att[\"SoT_att_90\"]\n",
    "        DaysRestDiff = home_rest - away_rest\n",
    "\n",
    "        # put it all together (wide row per match)\n",
    "        row = {\n",
    "            \"Round\": match[\"Round\"],\n",
    "            \"HomeTeam\": home,\n",
    "            \"AwayTeam\": away,\n",
    "\n",
    "            # context\n",
    "            \"Home_days_rest\": home_rest,\n",
    "            \"Away_days_rest\": away_rest,\n",
    "            \"DaysRestDiff\": DaysRestDiff,\n",
    "            \"Home_occ_prior\": occ_prior,\n",
    "            \"LeagueAvg_xG_perMatch_sofar\": league_xG_sofar,\n",
    "            \"LeagueAvg_Corners_perMatch_sofar\": league_corn_sofar,\n",
    "            \"HomeFlag\": 1,  # by definition row is from home POV\n",
    "\n",
    "            # home attacking form\n",
    "            \"Home_xG_att_90\": home_att[\"xG_att_90\"],\n",
    "            \"Home_SoT_att_90\": home_att[\"SoT_att_90\"],\n",
    "            \"Home_BigCh_att_90\": home_att[\"BigCh_att_90\"],\n",
    "            \"Home_Corn_att_90\": home_att[\"Corn_att_90\"],\n",
    "            \"Home_ToB_att_90\": home_att[\"ToB_att_90\"],\n",
    "\n",
    "            # home defensive form\n",
    "            \"Home_xGA_def_90\": home_def[\"xGA_def_90\"],\n",
    "            \"Home_SoT_agst_90\": home_def[\"SoT_agst_90\"],\n",
    "            \"Home_BigCh_agst_90\": home_def[\"BigCh_agst_90\"],\n",
    "\n",
    "            # away attacking form\n",
    "            \"Away_xG_att_90\": away_att[\"xG_att_90\"],\n",
    "            \"Away_SoT_att_90\": away_att[\"SoT_att_90\"],\n",
    "            \"Away_BigCh_att_90\": away_att[\"BigCh_att_90\"],\n",
    "            \"Away_Corn_att_90\": away_att[\"Corn_att_90\"],\n",
    "            \"Away_ToB_att_90\": away_att[\"ToB_att_90\"],\n",
    "\n",
    "            # away defensive form\n",
    "            \"Away_xGA_def_90\": away_def[\"xGA_def_90\"],\n",
    "            \"Away_SoT_agst_90\": away_def[\"SoT_agst_90\"],\n",
    "            \"Away_BigCh_agst_90\": away_def[\"BigCh_agst_90\"],\n",
    "\n",
    "            # composites\n",
    "            \"Home_AttackVsDefense\": Home_AttackVsDefense,\n",
    "            \"Away_AttackVsDefense\": Away_AttackVsDefense,\n",
    "            \"TempoSum\": TempoSum,\n",
    "            \"SoTSum\": SoTSum\n",
    "        }\n",
    "\n",
    "        feature_rows.append(row)\n",
    "\n",
    "        # --- AFTER computing features, update history and league aggregates with this match. ---\n",
    "        # This is critical for leak prevention: we only learn from the match AFTER we've created its pre-match row.\n",
    "\n",
    "        # update team_history for home\n",
    "        team_history[home].append({\n",
    "            \"date\": match[\"date\"],\n",
    "            \"homeAway\": \"home\",\n",
    "            \"opponent\": away,\n",
    "            \"minutes\": match[\"minutes\"],\n",
    "            \"occupancy\": match[\"occupancy\"],\n",
    "            \"xG_for\": match[\"xG_home\"],\n",
    "            \"SoT_for\": match[\"SoT_home\"],\n",
    "            \"BigCh_for\": match[\"BigCh_home\"],\n",
    "            \"Corn_for\": match[\"Corn_home\"],\n",
    "            \"ToB_for\": match[\"ToB_home\"],\n",
    "            \"xG_against\": match[\"xG_away\"],\n",
    "            \"SoT_against\": match[\"SoT_away\"],\n",
    "            \"BigCh_against\": match[\"BigCh_away\"]\n",
    "        })\n",
    "\n",
    "        # update team_history for away\n",
    "        team_history[away].append({\n",
    "            \"date\": match[\"date\"],\n",
    "            \"homeAway\": \"away\",\n",
    "            \"opponent\": home,\n",
    "            \"minutes\": match[\"minutes\"],\n",
    "            \"occupancy\": match[\"occupancy\"],\n",
    "            \"xG_for\": match[\"xG_away\"],\n",
    "            \"SoT_for\": match[\"SoT_away\"],\n",
    "            \"BigCh_for\": match[\"BigCh_away\"],\n",
    "            \"Corn_for\": match[\"Corn_away\"],\n",
    "            \"ToB_for\": match[\"ToB_away\"],\n",
    "            \"xG_against\": match[\"xG_home\"],\n",
    "            \"SoT_against\": match[\"SoT_home\"],\n",
    "            \"BigCh_against\": match[\"BigCh_home\"]\n",
    "        })\n",
    "\n",
    "        # update league per-team running totals\n",
    "        mins = match[\"minutes\"]\n",
    "        global_team_minutes += mins * 2\n",
    "        global_xG_sum += match[\"xG_home\"] + match[\"xG_away\"]\n",
    "        global_SoT_sum += match[\"SoT_home\"] + match[\"SoT_away\"]\n",
    "        global_BigCh_sum += match[\"BigCh_home\"] + match[\"BigCh_away\"]\n",
    "        global_Corn_sum += match[\"Corn_home\"] + match[\"Corn_away\"]\n",
    "        global_ToB_sum += match[\"ToB_home\"] + match[\"ToB_away\"]\n",
    "\n",
    "        if match[\"occupancy\"] is not None:\n",
    "            global_occ_sum += match[\"occupancy\"]\n",
    "            global_occ_n += 1\n",
    "\n",
    "        # league-wide match context\n",
    "        global_match_count += 1\n",
    "        global_match_xG_sum += (match[\"xG_home\"] + match[\"xG_away\"])\n",
    "        global_match_corners_sum += (match[\"Corn_home\"] + match[\"Corn_away\"])\n",
    "\n",
    "############################################################\n",
    "# Merge in the SLS_Fplus target and save CSVs\n",
    "############################################################\n",
    "\n",
    "wide_df = pd.DataFrame(feature_rows)\n",
    "\n",
    "# Load SLS table; we assume it has Round, HomeTeam, AwayTeam, SLS_Fplus\n",
    "sls_df = pd.read_csv(SLS_TABLE_PATH)\n",
    "\n",
    "# Minimal subset of columns we need from sls_df\n",
    "# We assume sls_df columns include [\"Round\",\"HomeTeam\",\"AwayTeam\",\"SLS_Fplus\"]\n",
    "if \"SLS_Fplus\" not in sls_df.columns:\n",
    "    # Some earlier code may have named it differently like \"SLS_Fplus\"\n",
    "    # Adjust here if needed.\n",
    "    pass\n",
    "\n",
    "model_df = pd.merge(\n",
    "    wide_df,\n",
    "    sls_df[[\"Round\",\"HomeTeam\",\"AwayTeam\",\"SLS_Fplus\"]],\n",
    "    on=[\"Round\",\"HomeTeam\",\"AwayTeam\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Save wide match-level feature table\n",
    "wide_out_path = os.path.join(OUT_DIR, \"match_features_wide.csv\")\n",
    "model_df.to_csv(wide_out_path, index=False)\n",
    "\n",
    "# Also build long format (one row per team per match) for per-team exploration\n",
    "long_rows = []\n",
    "for _,r in model_df.iterrows():\n",
    "    # home row\n",
    "    long_rows.append({\n",
    "        \"Round\": r[\"Round\"],\n",
    "        \"Team\": r[\"HomeTeam\"],\n",
    "        \"Role\": \"home\",\n",
    "        \"Opponent\": r[\"AwayTeam\"],\n",
    "        \"xG_att_90\": r[\"Home_xG_att_90\"],\n",
    "        \"SoT_att_90\": r[\"Home_SoT_att_90\"],\n",
    "        \"BigCh_att_90\": r[\"Home_BigCh_att_90\"],\n",
    "        \"Corn_att_90\": r[\"Home_Corn_att_90\"],\n",
    "        \"ToB_att_90\": r[\"Home_ToB_att_90\"],\n",
    "        \"xGA_def_90\": r[\"Home_xGA_def_90\"],\n",
    "        \"SoT_agst_90\": r[\"Home_SoT_agst_90\"],\n",
    "        \"BigCh_agst_90\": r[\"Home_BigCh_agst_90\"],\n",
    "        \"Days_rest\": r[\"Home_days_rest\"],\n",
    "        \"Occ_prior\": r[\"Home_occ_prior\"],\n",
    "        \"AttackVsDefense\": r[\"Home_AttackVsDefense\"],\n",
    "        \"TempoSum\": r[\"TempoSum\"],\n",
    "        \"SoTSum\": r[\"SoTSum\"],\n",
    "        \"LeagueAvg_xG_perMatch_sofar\": r[\"LeagueAvg_xG_perMatch_sofar\"],\n",
    "        \"LeagueAvg_Corners_perMatch_sofar\": r[\"LeagueAvg_Corners_perMatch_sofar\"],\n",
    "        \"SLS_Fplus\": r[\"SLS_Fplus\"]\n",
    "    })\n",
    "    # away row\n",
    "    long_rows.append({\n",
    "        \"Round\": r[\"Round\"],\n",
    "        \"Team\": r[\"AwayTeam\"],\n",
    "        \"Role\": \"away\",\n",
    "        \"Opponent\": r[\"HomeTeam\"],\n",
    "        \"xG_att_90\": r[\"Away_xG_att_90\"],\n",
    "        \"SoT_att_90\": r[\"Away_SoT_att_90\"],\n",
    "        \"BigCh_att_90\": r[\"Away_BigCh_att_90\"],\n",
    "        \"Corn_att_90\": r[\"Away_Corn_att_90\"],\n",
    "        \"ToB_att_90\": r[\"Away_ToB_att_90\"],\n",
    "        \"xGA_def_90\": r[\"Away_xGA_def_90\"],\n",
    "        \"SoT_agst_90\": r[\"Away_SoT_agst_90\"],\n",
    "        \"BigCh_agst_90\": r[\"Away_BigCh_agst_90\"],\n",
    "        \"Days_rest\": r[\"Away_days_rest\"],\n",
    "        \"Occ_prior\": None,  # away team doesn't \"own\" stadium occupancy\n",
    "        \"AttackVsDefense\": r[\"Away_AttackVsDefense\"],\n",
    "        \"TempoSum\": r[\"TempoSum\"],\n",
    "        \"SoTSum\": r[\"SoTSum\"],\n",
    "        \"LeagueAvg_xG_perMatch_sofar\": r[\"LeagueAvg_xG_perMatch_sofar\"],\n",
    "        \"LeagueAvg_Corners_perMatch_sofar\": r[\"LeagueAvg_Corners_perMatch_sofar\"],\n",
    "        \"SLS_Fplus\": r[\"SLS_Fplus\"]\n",
    "    })\n",
    "\n",
    "long_df = pd.DataFrame(long_rows)\n",
    "\n",
    "long_out_path = os.path.join(OUT_DIR, \"match_features_long.csv\")\n",
    "long_df.to_csv(long_out_path, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(f\" - {wide_out_path}\")\n",
    "print(f\" - {long_out_path}\")\n",
    "print(\"Columns in wide file:\")\n",
    "print(model_df.columns.tolist())\n",
    "print(\"Columns in long file:\")\n",
    "print(long_df.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
